{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/playpen-storage/levlevi/anaconda3/envs/sceneparse/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from scenedetect import detect, AdaptiveDetector, split_video_ffmpeg, ContentDetector\n",
    "\n",
    "ex_vid_fp = \"/mnt/arc/levlevi/nba-positions-videos-dataset/nba-plus-statvu-dataset/clips/707/period1/707_period1_2+_76423285.mp4\"\n",
    "scene_list = detect(ex_vid_fp, AdaptiveDetector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "annotation_ex = \"/mnt/arc/levlevi/nba-positions-videos-dataset/nba-plus-statvu-dataset/clip-annotations/17600/period1/17600_period1_1-_77131343_annotation.json\"\n",
    "with open(annotation_ex, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "unique_keys = set()\n",
    "for item in data['frames']:\n",
    "    # print(item)\n",
    "    frame_id = item[\"frame_id\"]\n",
    "    if frame_id not in unique_keys:\n",
    "        unique_keys.add(frame_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['frames'][0]['bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# for each clip\n",
    "    # 1. do we have an annotation file?\n",
    "    # 2. parse clip into [segmented_clip]\n",
    "    # for each segmented_clip:\n",
    "        # a. longer than 2s?\n",
    "        # b. are bbxs present?\n",
    "        # c. avg # bbxs < 3 ?\n",
    "        # if all criteria are met:\n",
    "            # create new segmented_clip and annotation file using simple subset of og files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "all_clip_file_paths = glob(\n",
    "    \"/mnt/arc/levlevi/nba-positions-videos-dataset/nba-plus-statvu-dataset/clips\" + '/*/*/*.mp4'\n",
    ")\n",
    "all_annotations_paths = glob(\n",
    "    \"/mnt/arc/levlevi/nba-positions-videos-dataset/nba-plus-statvu-dataset/clip-annotations\"\n",
    "    + \"/*/*/*.json\"\n",
    ")\n",
    "all_annotation_basenames = set(list(\n",
    "    os.path.basename(fp).replace('.json', '.mp4').replace('_annotation', '') for fp in all_annotations_paths\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# all clips to process\n",
    "clips_w_ann_file_paths = [fp for fp in all_clip_file_paths if os.path.basename(fp) in all_annotation_basenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from scenedetect import detect\n",
    "from statistics import mean\n",
    "from typing import List, Tuple\n",
    "from scenedetect.frame_timecode import FrameTimecode\n",
    "\n",
    "\n",
    "MIN_SCENE_LEN = 2 * 30\n",
    "MIN_NUM_BBXS = 3\n",
    "THRESHOLD = 30\n",
    "\n",
    "detector = ContentDetector(threshold=THRESHOLD)\n",
    "\n",
    "def parse_scene(video_fp: str) -> List[Tuple]:\n",
    "    \n",
    "    def add_frame_length_info(interval):\n",
    "        def parse_frame_info(frame_info):\n",
    "            return int(frame_info)\n",
    "        def calculate_length_in_frames(start_info, end_info):\n",
    "            start_frame = parse_frame_info(start_info)\n",
    "            end_frame = parse_frame_info(end_info)\n",
    "            return end_frame - start_frame\n",
    "        start_info, end_info = interval\n",
    "        length_in_frames = calculate_length_in_frames(start_info, end_info)\n",
    "            # Return the original tuple with the frame length appended\n",
    "        return (start_info, end_info, length_in_frames)\n",
    "    \n",
    "    scene_list = detect(video_fp, detector)\n",
    "    return [add_frame_length_info(interval) for interval in scene_list]\n",
    "\n",
    "\n",
    "def filter_scenes(video_fp: str, scenes: List[Tuple]):\n",
    "    \"\"\"\n",
    "    Return scenes that are:\n",
    "        1. 2+ sec. in length\n",
    "        2. contain an avg. of 3+ bbxs\n",
    "    \"\"\"\n",
    "\n",
    "    # look up annotation fp\n",
    "    annotation_fp = video_fp.replace(\"clips\", \"clip-annotations\").replace(\n",
    "        \".mp4\", \"_annotation.json\"\n",
    "    )\n",
    "    # load data\n",
    "    with open(annotation_fp, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # find all frames w/ bbxs\n",
    "    unique_keys = set()\n",
    "    for item in data[\"frames\"]:\n",
    "        frame_id = item[\"frame_id\"]\n",
    "        if frame_id not in unique_keys:\n",
    "            unique_keys.add(int(frame_id))\n",
    "\n",
    "    # num frames to parse\n",
    "    final_frame = int(cv2.VideoCapture(video_fp).get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # count bbxs\n",
    "    # [# bbxs]\n",
    "    num_bbxs = []\n",
    "    for frame_idx in range(final_frame):\n",
    "        if frame_idx not in unique_keys:\n",
    "            num_bbxs.append(0)\n",
    "        else:\n",
    "            num_bbx_tmp = len(data[\"frames\"][frame_idx][\"bbox\"])\n",
    "            num_bbxs.append(num_bbx_tmp)\n",
    "\n",
    "    # edge case\n",
    "    if len(scenes) == 0:\n",
    "        if mean(num_bbxs) < MIN_NUM_BBXS:\n",
    "            return []\n",
    "        else:\n",
    "            return [(FrameTimecode(0, fps=30), FrameTimecode(final_frame, fps=30), final_frame)]\n",
    "\n",
    "    filtered_scenes = []\n",
    "    # filter scenes\n",
    "    for scene in scenes:\n",
    "        # 1. longer than 2s?\n",
    "        scene_start = scene[0].frame_num\n",
    "        scene_end = scene[1].frame_num\n",
    "        if scene_end - scene_start < MIN_SCENE_LEN:\n",
    "            continue\n",
    "        # 2. avg # bbxs < 3?\n",
    "        if mean(num_bbxs[scene_start: scene_end]) < MIN_NUM_BBXS:\n",
    "            continue\n",
    "        filtered_scenes.append(scene)\n",
    "\n",
    "    return filtered_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(00:00:00.000 [frame=0, fps=30.000],\n",
       "  00:00:11.067 [frame=332, fps=30.000],\n",
       "  332)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_ex = clips_w_ann_file_paths[1]\n",
    "scenes = parse_scene(clip_ex)\n",
    "filtered_scenes = filter_scenes(clip_ex, scenes)\n",
    "filtered_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_ex = clips_w_ann_file_paths[0]\n",
    "scenes = parse_scene(clip_ex)\n",
    "scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sceneparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
