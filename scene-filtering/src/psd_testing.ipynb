{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from scenedetect import detect, AdaptiveDetector, split_video_ffmpeg, ContentDetector\n",
    "\n",
    "ex_vid_fp = \"/mnt/arc/levlevi/nba-positions-videos-dataset/nba-plus-statvu-dataset/clips/707/period1/707_period1_2+_76423285.mp4\"\n",
    "scene_list = detect(ex_vid_fp, AdaptiveDetector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "annotation_ex = \"/mnt/arc/levlevi/nba-positions-videos-dataset/nba-plus-statvu-dataset/clip-annotations/17600/period1/17600_period1_1-_77131343_annotation.json\"\n",
    "with open(annotation_ex, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "unique_keys = set()\n",
    "for item in data['frames']:\n",
    "    # print(item)\n",
    "    frame_id = item[\"frame_id\"]\n",
    "    if frame_id not in unique_keys:\n",
    "        unique_keys.add(frame_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['frames'][0]['bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# for each clip\n",
    "    # 1. do we have an annotation file?\n",
    "    # 2. parse clip into [segmented_clip]\n",
    "    # for each segmented_clip:\n",
    "        # a. longer than 2s?\n",
    "        # b. are bbxs present?\n",
    "        # c. avg # bbxs < 3 ?\n",
    "        # if all criteria are met:\n",
    "            # create new segmented_clip and annotation file using simple subset of og files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "all_clip_file_paths = glob(\n",
    "    \"/mnt/arc/levlevi/nba-positions-videos-dataset/nba-plus-statvu-dataset/clips\" + '/*/*/*.mp4'\n",
    ")\n",
    "all_annotations_paths = glob(\n",
    "    \"/mnt/arc/levlevi/nba-positions-videos-dataset/nba-plus-statvu-dataset/clip-annotations\"\n",
    "    + \"/*/*/*.json\"\n",
    ")\n",
    "all_annotation_basenames = set(list(\n",
    "    os.path.basename(fp).replace('.json', '.mp4').replace('_annotation', '') for fp in all_annotations_paths\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# all clips to process\n",
    "clips_w_ann_file_paths = [fp for fp in all_clip_file_paths if os.path.basename(fp) in all_annotation_basenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from scenedetect import detect\n",
    "from statistics import mean\n",
    "from typing import List, Tuple\n",
    "from scenedetect.frame_timecode import FrameTimecode\n",
    "\n",
    "\n",
    "MIN_SCENE_LEN = 2 * 30\n",
    "MIN_NUM_BBXS = 3\n",
    "THRESHOLD = 30\n",
    "FPS = 30\n",
    "\n",
    "detector = ContentDetector(threshold=THRESHOLD)\n",
    "\n",
    "def parse_scene(video_fp: str) -> List[Tuple]:\n",
    "\n",
    "    def add_frame_length_info(interval):\n",
    "        def parse_frame_info(frame_info):\n",
    "            return int(frame_info)\n",
    "        def calculate_length_in_frames(start_info, end_info):\n",
    "            start_frame = parse_frame_info(start_info)\n",
    "            end_frame = parse_frame_info(end_info)\n",
    "            return end_frame - start_frame\n",
    "        start_info, end_info = interval\n",
    "        length_in_frames = calculate_length_in_frames(start_info, end_info)\n",
    "        # Return the original tuple with the frame length appended\n",
    "        return (start_info, end_info, length_in_frames)\n",
    "\n",
    "    scene_list = detect(video_fp, detector)\n",
    "    return [add_frame_length_info(interval) for interval in scene_list]\n",
    "\n",
    "\n",
    "def filter_scenes(video_fp: str, scenes: List[Tuple]) -> List[Tuple]:\n",
    "    \"\"\"\n",
    "    Return scenes that are:\n",
    "        1. 2+ sec. in length\n",
    "        2. contain an avg. of 3+ bbxs\n",
    "    \"\"\"\n",
    "\n",
    "    # look up annotation fp\n",
    "    annotation_fp = video_fp.replace(\"clips\", \"clip-annotations\").replace(\n",
    "        \".mp4\", \"_annotation.json\"\n",
    "    )\n",
    "    # load data\n",
    "    with open(annotation_fp, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # find all frames w/ bbxs\n",
    "    unique_keys = set()\n",
    "    for item in data[\"frames\"]:\n",
    "        frame_id = item[\"frame_id\"]\n",
    "        if frame_id not in unique_keys:\n",
    "            unique_keys.add(int(frame_id))\n",
    "\n",
    "    # num frames to parse\n",
    "    final_frame = int(cv2.VideoCapture(video_fp).get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # count bbxs\n",
    "    # [# bbxs]\n",
    "    num_bbxs = []\n",
    "    for frame_idx in range(final_frame):\n",
    "        if frame_idx not in unique_keys:\n",
    "            num_bbxs.append(0)\n",
    "        else:\n",
    "            num_bbx_tmp = len(data[\"frames\"][frame_idx][\"bbox\"])\n",
    "            num_bbxs.append(num_bbx_tmp)\n",
    "\n",
    "    # edge case\n",
    "    if len(scenes) == 0:\n",
    "        if mean(num_bbxs) < MIN_NUM_BBXS:\n",
    "            return []\n",
    "        else:\n",
    "            return [\n",
    "                (\n",
    "                    FrameTimecode(0, fps=FPS),\n",
    "                    FrameTimecode(final_frame, fps=FPS),\n",
    "                    final_frame,\n",
    "                )\n",
    "            ]\n",
    "\n",
    "    filtered_scenes = []\n",
    "    # filter scenes\n",
    "    for scene in scenes:\n",
    "        # 1. longer than 2s?\n",
    "        scene_start = scene[0].frame_num\n",
    "        scene_end = scene[1].frame_num\n",
    "        if scene_end - scene_start < MIN_SCENE_LEN:\n",
    "            continue\n",
    "        # 2. avg # bbxs < 3?\n",
    "        if mean(num_bbxs[scene_start: scene_end]) < MIN_NUM_BBXS:\n",
    "            continue\n",
    "        filtered_scenes.append(scene)\n",
    "\n",
    "    return filtered_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_new_clip(video_path: str, dst_path: str, scene):\n",
    "    # save a new clip\n",
    "    start_frame = scene[0].frame_num\n",
    "    end_frame = scene[1].frame_num\n",
    "    cmd = f\"ffmpeg -hide_banner -loglevel error -i {video_path} -ss {start_frame} -to {end_frame} -c:v libx264 -crf 23 -preset medium -c:a copy {dst_path}\"\n",
    "    os.system(cmd)\n",
    "\n",
    "def create_new_annotation(annotation_path: str, dst_path: str, scene):\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    new_annotation = {\"video_id\": None, \"video_path\": None, \"frames\": []}\n",
    "    new_annotation[\"video_id\"] = data[\"video_id\"]\n",
    "    new_annotation[\"video_path\"] = data[\"video_path\"]\n",
    "\n",
    "    start_frame = scene[0].frame_num\n",
    "    end_frame = scene[1].frame_num\n",
    "    frames = []\n",
    "    for frame in data[\"frames\"]:\n",
    "        if frame[\"frame_id\"] >= start_frame and frame[\"frame_id\"] <= end_frame:\n",
    "            frames.append(frame)\n",
    "    new_annotation[\"frames\"] = frames\n",
    "    \n",
    "    with open(dst_path, 'w') as f:\n",
    "        json.dump(new_annotation, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_dst_dir: /mnt/arc/levlevi/nba-positions-videos-dataset/nba-plus-statvu-dataset/filtered-clips/18081/period2\n",
      "created /mnt/arc/levlevi/nba-positions-videos-dataset/nba-plus-statvu-dataset/filtered-clips/18081/period2/18081_period2_2-_76872867_0.mp4 and \n",
      "/mnt/arc/levlevi/nba-positions-videos-dataset/nba-plus-statvu-dataset/filtered-clip-annotations/18081/period2\n"
     ]
    }
   ],
   "source": [
    "clip_ex = clips_w_ann_file_paths[1]\n",
    "scenes = parse_scene(clip_ex)\n",
    "filtered_scenes = filter_scenes(clip_ex, scenes)\n",
    "\n",
    "for fp in clips_w_ann_file_paths:\n",
    "    scenes = parse_scene(fp)\n",
    "    filtered_scenes = filter_scenes(fp, scenes)\n",
    "\n",
    "    video_dst_path = fp.replace(\"clips\", \"filtered-clips\")\n",
    "    video_dst_dir = os.path.dirname(video_dst_path)\n",
    "    print(f\"video_dst_dir: {video_dst_dir}\")\n",
    "\n",
    "    # find annotation file\n",
    "    annotation_path = fp.replace(\"clips\", \"clip-annotations\").replace(\".mp4\", \"_annotation.json\")\n",
    "    annotation_dst_path = fp.replace(\"clips\", \"filtered-clip-annotations\").replace(\".mp4\", \"_annotation.json\")\n",
    "    annotation_dst_dir = os.path.dirname(annotation_dst_path)\n",
    "\n",
    "    # recursive create dirs if doesn't exist\n",
    "    os.makedirs(video_dst_dir, exist_ok=True)\n",
    "    os.makedirs(annotation_dst_dir, exist_ok=True)\n",
    "\n",
    "    for scene_num, scene in enumerate(filtered_scenes):\n",
    "        video_dst_path = video_dst_path.replace(\".mp4\", f\"_{scene_num}.mp4\")\n",
    "        annotation_dst_path = annotation_dst_path.replace(\".json\", f\"_{scene_num}.json\")\n",
    "        create_new_clip(fp, video_dst_path, scene)\n",
    "        create_new_annotation(annotation_path, annotation_dst_path, scene)\n",
    "        print(f\"created {video_dst_path} and \\n{annotation_dst_path}\")\n",
    "        break\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(00:00:00.000 [frame=0, fps=30.000],\n",
       "  00:00:11.067 [frame=332, fps=30.000],\n",
       "  332)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_ex = clips_w_ann_file_paths[1]\n",
    "scenes = parse_scene(clip_ex)\n",
    "scenes = filter_scenes(clip_ex, scenes)\n",
    "scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sceneparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
